--- Libraries:
arguments = require 'Settings.arguments'
constants = require 'Settings.constants'
card_to_string = require 'Game.card_to_string_conversion'
card_tools = require 'Game.card_tools'
game_settings = require 'Settings.game_settings'

require 'torch'
require 'math'
require 'Tree.tree_builder'
require 'Tree.tree_data_generation'
require 'Tree.tree_visualiser'

require 'Tree.tree_cfr'
require 'TerminalEquity.terminal_equity'


local StrategyEvaluator = torch.class('StrategyEvaluator')

function StrategyEvaluator:__init(tree1,tree2)
  self.agents_table = {tree1,tree2}
  self.card1_range = torch.FloatTensor(1,game_settings.card_count):fill(0)
  self.card2_range = torch.FloatTensor(1,game_settings.card_count):fill(0)
  self.terminal_equity = TerminalEquity()
  self.card1 = 0
  self.card2 = 0
  self.board = 0
  self:initialize_cards()
  self.A1 = 1
  self.A2 = 2
  self.chance = 0
  self.A1_pot = 0
  self.A2_pot = 0
  self.history_actions ={}
  self.terminal_equity:set_board(torch.FloatTensor({self.board}))
  self.new_current_agent = 0
  self.last_to_play = 0
  self.current_winner = 0
  self.winners_table = {}
  self.A1_pot_tensor = torch.FloatTensor()
  self.A2_pot_tensor = torch.FloatTensor()
  self.A2_pot_matrix = torch.FloatTensor()
end



--- Function that initialize the cards for each player and the board
function StrategyEvaluator:initialize_cards()
  local cards = torch.randperm(game_settings.card_count)
  local card1 = cards[1]
  local card2 = cards[2]
  local board = cards[3]
  self.card1 = card1
  self.card2 = card2
  self.board = board
  self.card1_range[1][card1] = 1
  self.card2_range[1][card2] = 1
  self.terminal_equity:set_board(torch.FloatTensor({board}))
end


--- Update  the players table
function StrategyEvaluator:update_players_table(partial_tree1,partial_tree2)
  ---if agent_to_act == self.A2 then
    ---self.agents_table = {partial_tree2,partial_tree1}
  ---else
    self.agents_table = {partial_tree1,partial_tree2}
  ---end
end

--- Set the pots to 0
function StrategyEvaluator:initialize_pots()
  self.A1_pot = 0
  self.A2_pot = 0
end

----Increases winner pot, decreases loosers pot
function StrategyEvaluator:update_pot(winner,node)

  if winner == 1 then
    self.A1_pot = self.A1_pot + node.pot
    self.A2_pot = self.A2_pot - node.pot
  elseif winner ==2 then
    self.A1_pot = self.A1_pot - node.pot
    self.A2_pot = self.A2_pot + node.pot
  end

end


--- Receives a node and generates an action_dimension
function StrategyEvaluator:generate_action(tree_current_agent,current_agent)
  --- Set who is the player
  local card = 0
  if current_agent == self.A1 then
    --- print("card1")
    card = self.card1
  else
    ---print("card2")
    card = self.card2
  end
  --- Generate an action according to the strategy_indexes
  ---print(card)
  ---print(node.strategy)
  ---print("play agent", current_agent)

  local strategy = tree_current_agent.strategy[{{},card}]:clone()
  ---print(strategy)
  local action = torch.multinomial(strategy, 1)[1]
  ---print("action taken", action)
  return action
end


--- Calculates the winner of the round
function StrategyEvaluator:compute_winner(leaf_last_agent)
  local current_player = leaf_last_agent.current_player
  local last_agent_to_play = self.last_to_play

  ---assert(current_player == last_agent_to_play, "last player and current_agent dont match")
  local opponent_player = 3-leaf_last_agent.current_player

  local last_action = torch.Tensor(self.history_actions)[-1]
  ---print(last_action)
  if  last_action == 1 then
    assert(leaf_last_agent.terminal == true, "not terminal node")
    local opponent_to_fold_agent = 3 - last_agent_to_play
    ---print("player fold", last_agent_to_play)
    return opponent_to_fold_agent
  else
    local equity_matrix = self.terminal_equity.equity_matrix
    local agent1_result = equity_matrix[self.card2][self.card1]
    if agent1_result > 0 then
      return 1
    elseif agent1_result < 0 then
      return 2
    else
      return 0
    end
  end

end



--- Iteratevely we walk both trees generating actions until the game is over
function StrategyEvaluator:play_game(node1,node2,agent_to_act)
  ---local actual_players_table = {node1,node2}
  --- Index the current player and the opponent
  local current_agent = agent_to_act
  local opponent_agent = 3 - current_agent
  ---Update the players table:
  self:update_players_table(node1,node2)

  --- Indexing the trees
  local tree_current_agent = self.agents_table[1]---[current_agent]
  local tree_opponent_agent = self.agents_table[2]---[opponent_agent]

  --- Indexing the children
  local children_current = tree_current_agent.children
  local children_opponent = tree_opponent_agent.children

  --- Number of children:
  local num_children = #tree_current_agent.children
  assert(num_children == #tree_opponent_agent.children, "different number of children")

  if node1.current_player == 0 then
    assert(node1.current_player == node2.current_player,"agents not in the same branches")
    local chance_index = self.board
    local new_current_agent = self.new_current_agent
    ---print("chance",chance_index)
    self:play_game(children_current[chance_index],children_opponent[chance_index],new_current_agent)

  else
    --- if the last player was the chance then
    if num_children > 0 then
      ---Next Player
      ---print("agent: ", current_agent)
      local action_index = self:generate_action(tree_current_agent, current_agent)
      ---print("action taken: ",action_index)
      table.insert(self.history_actions,action_index)
      ---print("new_current_agent",opponent_agent)
      self.new_current_agent = opponent_agent
      self.last_to_play = current_agent
      self:play_game(children_opponent[action_index],children_current[action_index],opponent_agent)

    else
      local winner = self:compute_winner(tree_current_agent)
      self.current_winner = winner
      ---print("winner", winner)
      self:update_pot(winner,tree_current_agent)

    end
  end
end


--- Plays several times an agent against another agent
function StrategyEvaluator:play_several_games(tree1,tree2,number_of_games)
  local starting_player = 1
  local tree1 = tree1 or self.agents_table[1]
  local tree2 = tree2 or self.agents_table[2]



  for i = 1,number_of_games do
    ---print(starting_player)
    --- Set pots to 0
    self:initialize_pots()
    if i %2 == 1 then
      self:play_game(tree1,tree2,starting_player)
    else
      self:play_game(tree2,tree1,starting_player+1)
    end
    table.insert(self.winners_table,self.current_winner)
    self:initialize_cards()
  end
  ---self:display_results()
  self.winners_table = {}
  collectgarbage()
end




--- Function that initialize the cards for each player and the board
function StrategyEvaluator:initialize_fixed_cards(cards)
  local card1 = cards.P1
  local card2 = cards.P2
  local board = cards.board
  self.card1 = card1
  self.card2 = card2
  self.board = board
  self.card1_range[1][card1] = 1
  self.card2_range[1][card2] = 1
  self.terminal_equity:set_board(torch.FloatTensor({board}))
end




--- Plays several times an agent against another agent
function StrategyEvaluator:play_deterministic_games(tree1,tree2,number_of_games,cards)
  local starting_player = 0
  local tree1 = tree1 or self.agents_table[1]
  local tree2 = tree2 or self.agents_table[2]
  --- Set pots to 0
  self:initialize_pots()
  self:initialize_fixed_cards(cards)
  for i = 1,number_of_games do
    ---print(starting_player)

    self:play_game(tree1,tree2,starting_player+1)
    table.insert(self.winners_table,self.current_winner)
    starting_player = (starting_player+1)%2
  end
  ---self:display_results()
  ---self.winners_table = {}
  collectgarbage()
end


function StrategyEvaluator:get_first_mask_tensor(index)
    local output = torch.range(1,6)
    if index ==1 then
        return torch.range(2,6)
    end
    local out1 = output:clone():narrow(1,1,index-1)
    local out2 = output:clone():narrow(1,index+1,6-index)
    local result = out1:cat(out2)
    return result
end

function StrategyEvaluator:get_second_mask_tensor(input_tensor,index)
    local result = {}
    local input = input_tensor:clone()
    for i = 1,input:size(1) do
        if input[i] ~= index then
            table.insert(result,input[i])
        end
    end
    return torch.Tensor(result)
end


function StrategyEvaluator:construct_possible_game_states()
    local states_tensor = torch.Tensor()
    local first_card_tensor = torch.Tensor({1,3,5})
    for i = 1,first_card_tensor:size(1) do
        local second_card_tensor = self:get_first_mask_tensor(first_card_tensor[i])
        for j =1, second_card_tensor:size(1) do
            local third_card_tensor = self:get_second_mask_tensor(second_card_tensor,second_card_tensor[j])
            for k = 1,third_card_tensor:size(1) do
                local states = torch.Tensor({first_card_tensor[i],second_card_tensor[j],third_card_tensor[k]}):view(1,3)
                states_tensor = states_tensor:cat(states,1)
            end
        end
    end
    return states_tensor
end


function StrategyEvaluator:initialize_winners_table()
  self.winners_table = {}
  collectgarbage()
end

function StrategyEvaluator:distribute_cards(cards_tensor)
    local cards = {}
    cards.P1 = cards_tensor[1]
    cards.P2 = cards_tensor[2]
    cards.board = cards_tensor[3]
    return cards
end




--- Plays several times an agent against another agent
function StrategyEvaluator:play_cards_n_times(tree1,tree2,number_of_games,cards)
  local starting_player = 1
  local tree1 = tree1 or self.agents_table[1]
  local tree2 = tree2 or self.agents_table[2]
  local pot2_table = {}


  --- Set pots to 0
  self:initialize_fixed_cards(cards)
  -- Initialize the pots:
  ---self:initialize_pots()

  for i = 1,number_of_games do
    -- Initialize the pots:
    self:initialize_pots()
    if i %2 == 1 then
      self:play_game(tree1,tree2,starting_player)
    else
      self:play_game(tree2,tree1,starting_player+1)
    end

    table.insert(self.winners_table,self.current_winner)
    table.insert(pot2_table,self.A2_pot)

  end
  ---self:display_results()
  ---self.winners_table = {}

  self.A2_pot_tensor = torch.FloatTensor(pot2_table)
  collectgarbage()
end




--- Plays several times an agent against another agent
function StrategyEvaluator:play_all_combinations_n_times(tree1,tree2,number_of_games)
  self:initialize_winners_table()

  self.A2_pot_matrix = torch.FloatTensor()
  local cards_tensor = construct_possible_game_states()
  for i = 1,cards_tensor:size(1) do
    local cards = distribute_cards(cards_tensor[i])
    tree_eval:play_cards_n_times(tree1,tree2,number_of_games,cards)
    local results_game = self.A2_pot_tensor:view(1,-1):clone()
    self.A2_pot_matrix = self.A2_pot_matrix:cat(results_game,1)
  end
  collectgarbage()
end

--- Displays the number of wins, loss and ties
function StrategyEvaluator:display_results()
  local p1_wins = 0
  local p2_wins = 0
  local tie = 0
  local wins_tensor = torch.Tensor(self.winners_table)
  if wins_tensor:size(1) >0 then
    for i =1,wins_tensor:size(1) do
      if wins_tensor[i] ==1 then
        p1_wins = p1_wins+1
      elseif wins_tensor[i] ==2 then
        p2_wins = p2_wins+1
      else
        tie = tie +1
      end
    end
    print("ties: ",tie)
    print("P1 won: ",p1_wins)
    print("P2 won: ",p2_wins)
  end
end
